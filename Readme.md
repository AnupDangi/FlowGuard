# Event-Driven Data Engineering Platform

**Learning Path: Building Real-Time Data Pipelines from Scratch**

I wanted to learn data engineering, so I learned by building projects - from basic concepts to production-grade systems.

---

## Learning Path

### 1. PySpark Fundamentals âœ…

**Location:** `learntools/pyspark/`

Master distributed data processing concepts:

- DataFrames, RDDs, transformations vs actions
- Partitioning, shuffling, skew handling
- Joins (broadcast, sort-merge, shuffle hash)
- Caching strategies (memory, disk, serialized)
- Query optimization and execution plans

ðŸ“– [See PySpark README](learntools/pyspark/README.md)

---

### 2. Apache Kafka âœ…

**Location:** `learntools/kafka/`

Learn distributed streaming and message queuing:

- Producer/Consumer architecture
- Topics, partitions, replication factor
- Message ordering guarantees
- Real-time ingestion patterns
- Fault tolerance and exactly-once semantics

ðŸ“– [See Kafka README](learntools/kafka/README.md)

---

### 3. Mini Project 1: Kafka + Spark Streaming âœ…

**Location:** `learntools/miniproject1/`

**What You'll Learn:**
Real-time order processing pipeline using Kafka producers and Spark Structured Streaming for live data transformation.

ðŸ“– [See Mini Project 1 README](learntools/miniproject1/README.md)

---

### 4. Apache Airflow âœ…

**Location:** `learntools/airflow/`

Master workflow orchestration:

- DAGs, tasks, operators
- TaskFlow API (Airflow 2.x)
- Scheduling, backfilling, catchup
- XCom for inter-task communication
- Error handling and retries

ðŸ“– [See Airflow README](learntools/airflow/README.md)

---

### 5. Mini Project 2: Medallion Architecture âœ… COMPLETED

**Location:** `learntools/miniproject2/`

**What You'll Learn:**
End-to-end ETL pipeline simulating Zomato delivery analytics - streaming ingestion (1000 events/sec), batch processing with Airflow + PySpark, Hive-style partitioning, all running locally.

**Achievements:**

- 11M+ events processed
- 79 Bronze files (9.1GB)
- 241+ CSV replay cycles
- Silver/Gold layers populated

ðŸ“– [See Mini Project 2 README](learntools/miniproject2/README.md)

---

### 6. Apache Flink ðŸš§ IN PROGRESS

**Location:** `learntools/flink/`

Advanced stream processing:

- Stateful computations
- Event time processing
- Windowing (tumbling, sliding, session)
- Watermarks and late data handling
- Exactly-once state consistency

ðŸ“– [See Flink README](learntools/flink/README.md)

---

## Major Project: Zomato Real-Time Data Engineering Platform ðŸŽ¯ NEXT

### Technologies Stack

We're using free Apache-based open-source stack:

![Zomato Tech Stack](./ZomatoStack.png)

- **Apache Kafka** - Real-time data streaming
- **Apache Hadoop** - Big data storage foundation
- **Apache Spark** - Large-scale data transformation
- **Apache Flink** - Real-time stream processing
- **Apache Airflow** - Workflow orchestration
- **Snowflake** - Cloud data warehouse for storage

### What We're Building

![Zomato Real-Time Ads Platform](./ZomatoDataEngineering.png)

**Real-time ads billing simulation for Zomato:**

- Events Gateway â†’ Kafka â†’ Flink SQL processes clicks/impressions
- Raw events stored in Data Lake
- Recon ETL Job runs at regular intervals
- Kafka publishes incremental updates
- Redis caches data for Ads Billing Engine

### Reference Architecture

![AWS Data Engineering Stack](./DataEngineering.png)

Example of complete data engineering cycle using Amazon stack (for reference only).

---

## Project Structure

```
FlowGuard/
â”œâ”€â”€ learntools/
â”‚   â”œâ”€â”€ pyspark/          # Distributed data processing âœ…
â”‚   â”œâ”€â”€ kafka/            # Streaming and messaging âœ…
â”‚   â”œâ”€â”€ miniproject1/     # Kafka + Spark integration âœ…
â”‚   â”œâ”€â”€ airflow/          # Workflow orchestration âœ…
â”‚   â”œâ”€â”€ miniproject2/     # Medallion ETL pipeline âœ…
â”‚   â””â”€â”€ flink/            # Advanced stream processing ðŸš§
â”‚
â””â”€â”€ major-project/        # Production Zomato simulation ðŸŽ¯
    â”œâ”€â”€ kafka-cluster/    # Multi-broker setup
    â”œâ”€â”€ flink-jobs/       # Real-time processing
    â”œâ”€â”€ airflow-dags/     # Batch orchestration
    â”œâ”€â”€ snowflake-setup/  # Data warehouse config
    â””â”€â”€ monitoring/       # Prometheus + Grafana
```

---

## Progress Timeline

- I actually learnt these all within 2 weeks,watched short yt videos read blogs and build project alongside to learn.

## References

- [Zomato Tech Blog on Data Engineering](https://www.zomato.com/blog/eliminating-bottlenecks-in-real-time-data-streaming-a-zomato-ads-flink-journey/)

- [Notion Tracker](https://www.notion.so/January-2db64cdddab780468bace3df7d1592ae)

- [Medallion Architecture](https://medium.com/@yudayreddy1/understanding-bronze-silver-and-gold-layers-in-data-engineering-5dd748b71d35)

---

**Current Status**: Mini Project 2 Completed âœ… | Starting Flink ðŸš§  
**Next**: Flink fundamentals â†’ Major Project kickoff
