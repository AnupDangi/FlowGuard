https://www.notion.so/January-2db64cdddab780468bace3df7d1592ae?source=copy_link

I am buliding Event-Driven Data Engineering Platform for Real-Time Decisions for Zomato Platform.

This architecture might change in the next upcoming weeks.
But for the week 1 this is the template.

![Architecture Diagram](architecture.excalidraw)

Week2: Learning all unkown the tools and making sure the architecture can be enhanced for betterment.

- Didnt got much time due to college exam but learnt about pyspark and how to use. learnt skew,jobs,mistakes which we do while writing query how the jobs are executed how to join,when to cache and how to cache properly,partitions.
- Now moving towards kafka and then event streaming and handling data pipelines into pyspark and storage into three different levels bronze(which is raw data),silver cleaned and transformed data,gold which is used for domain wize analytics and decision making.
- Read this for data storage types: https://medium.com/@yudayreddy1/understanding-bronze-silver-and-gold-layers-in-data-engineering-5dd748b71d35

Week3: I will start implementing with dummy kafka logs,then move to data engineering pipeline and try to complete it by week4.Then 2 days build frontend and backend using AI basic crud routes,might not take more and integrate.
Then do unit testing in last few days.

Read the articles:
Generated Data into pipeline: https://medium.com/@simardeep.oberoi/building-a-data-streaming-pipeline-leveraging-kafka-spark-airflow-and-docker-16527f9e9142
